{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abolger13/Knn-Predictive/blob/main/NLP_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Z-i5i_PcHf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV9WW7voPcHj"
      },
      "source": [
        "# Natural Language Processing </a>\n",
        "\n",
        "## Assignment: K Nearest Neighbors Model for the IMDB Movie Review Dataset\n",
        "\n",
        "For the final project, build a K Nearest Neighbors model to predict the sentiment (positive or negative) of movie reviews. The dataset is originally hosted here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "Use the notebooks from the class and implement the model, train and test with the corresponding datasets.\n",
        "\n",
        "You can follow these steps:\n",
        "1. Read training-test data (Given)\n",
        "2. Train a KNN classifier (Implement)\n",
        "3. Make predictions on your test dataset (Implement)\n",
        "4. Expermintation (Implement)\n",
        "\n",
        "__You can use the KNN Classifier from here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf9gzc3NPcHm"
      },
      "source": [
        "## 1. Reading the dataset\n",
        "\n",
        "We will use the __pandas__ library to read our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R1S95FYPcHm"
      },
      "source": [
        "#### __Training data:__\n",
        "Let's read our training data. Here, we have the text and label fields. Labe is 1 for positive reviews and 0 for negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "imYuQ2EcPcHn",
        "outputId": "feb0a579-9ea8-4103-a64d-cc681105ed62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  This movie makes me want to throw up every tim...      0\n",
              "1  Listening to the director's commentary confirm...      0\n",
              "2  One of the best Tarzan films is also one of it...      1\n",
              "3  Valentine is now one of my favorite slasher fi...      1\n",
              "4  No mention if Ann Rivers Siddons adapted the m...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad2e6851-4b56-431b-b3a7-674d43cdb482\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This movie makes me want to throw up every tim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Listening to the director's commentary confirm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One of the best Tarzan films is also one of it...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Valentine is now one of my favorite slasher fi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No mention if Ann Rivers Siddons adapted the m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad2e6851-4b56-431b-b3a7-674d43cdb482')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad2e6851-4b56-431b-b3a7-674d43cdb482 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad2e6851-4b56-431b-b3a7-674d43cdb482');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aacc8991-6a94-43e4-a3a8-b6dec8895ac2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aacc8991-6a94-43e4-a3a8-b6dec8895ac2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aacc8991-6a94-43e4-a3a8-b6dec8895ac2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 25000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24904,\n        \"samples\": [\n          \"This movie got extremely silly when things started to happen. I couldn't care less about any of the characters; Susan Walters was so annoying, and the leading actor (forget his name) also got on my nerves. Can't quite remember how it ended and so forth but the whole idea of aliens possessing human bodies and all just seemed stupid in this film, things didn't quite carry off. My dad told me it's s stupid movie...I should've listened to him.\",\n          \"**Possible Spoilers Ahead**<br /><br />\\tJason (a.k.a. Herb) Evers is a brilliant brain surgeon who, along with wife Virginia Leith, is involved in the most lackluster onscreen car crash ever. Leith is decapitated and the doctor takes her severed noggin back to his mansion and rejuvenates the head in his lab. The mansion's exterior was allegedly filmed at Tarrytown's Lyndhurst estate; the lab scenes were apparently shot in somebody's basement. The bandaged head is kept alive on \\\"lab equipment\\\" that's almost cheap-looking enough for Ed Wood. Some of the library music\\u0096the movie's high point\\u0096later turned up in Andy Milligan's THE BODY BENEATH. Leith's head has some heavy metaphysical discourses with another of Ever's misfires, a mutant chained in the closet. Meanwhile, the good doc prowls strip joints looking for a body worthy of his wife's gabby noodle. The ending, in uncut prints, features some ahead-of-its-time splatter and dismemberment when the zucchini-headed monster comes out of the closet to bring the movie to a welcome close. This thing took three years to be released and then, audiences gave it the bad reception it richly deserved. Between this, PLAN 9 FROM OUTER SPACE and a few others, 1959 should have been declared The Year Of The Turkey.\",\n          \"I wasted my time and gave this show a chance. This has to be one of the worst new shows. If they gave an award to shows that suck THIS one should sweep the category. The acting is poor and the story line is contrived. Now Dinosaurs was a bit strange but at least it was entertaining. That show lasted three seasons and was finally scraped. This new show, based on an insurance companies commercials, is not funny and really has nothing going for it. Possibly the original commercials and the amount of times they were, and still are, repeated is what is wrong with this show. It just came to TV and already we are tired of seeing the \\\"caveman\\\" characters.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('https://raw.githubusercontent.com/aws-samples/aws-machine-learning-university-accelerated-nlp/master/data/final_project/imdb_train.csv', header=0)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5c7uQRYPcHn"
      },
      "source": [
        "#### __Test data:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DiBpa04fPcHo",
        "outputId": "584638bb-b57b-45b6-9d7b-87d210218a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  What I hoped for (or even expected) was the we...      0\n",
              "1  Garden State must rate amongst the most contri...      0\n",
              "2  There is a lot wrong with this film. I will no...      1\n",
              "3  To qualify my use of \"realistic\" in the summar...      1\n",
              "4  Dirty War is absolutely one of the best politi...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4c43400-9916-4cc9-88e1-c4bdf5b96bab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What I hoped for (or even expected) was the we...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Garden State must rate amongst the most contri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There is a lot wrong with this film. I will no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To qualify my use of \"realistic\" in the summar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty War is absolutely one of the best politi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4c43400-9916-4cc9-88e1-c4bdf5b96bab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4c43400-9916-4cc9-88e1-c4bdf5b96bab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4c43400-9916-4cc9-88e1-c4bdf5b96bab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a87eb9b1-f81e-4665-bdda-1be7dc528875\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a87eb9b1-f81e-4665-bdda-1be7dc528875')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a87eb9b1-f81e-4665-bdda-1be7dc528875 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 25000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24801,\n        \"samples\": [\n          \"Probably the worst movie I have ever seen. It is so cheesily filmed, the focus is not even on this supposed \\\"real half-caste\\\", it is more on the crew coming from Hollywood to make the movie. No cinematic significance whatsoever, and if I could take back the almost 1 1/2 hours that I spent watching this film, I would feel much better.<br /><br />At first, it starts out giving you the impression it will be filmed somewhat generically, like an actual Hollywood production. However, then they go into the narration of the story, and it's filmed so f***ing terribly. It's supposed to be a take on \\\"Blair Witch Project\\\" really, since they pretty much use what you would think is 'real camera footage', it's not, don't be fooled.<br /><br />Worst movie I have ever seen . . . on the positive side, it has like one semi-scary scene in it, and the visuals of the half-caste weren't too bad looking at all. DON'T RENT\",\n          \"I got to know \\u00c6ON back in the early 90s via television and I loved it...<br /><br />What did you like about it ? The cranky drawing style ? The flawless artistic action involved ? The absurd and deadpan communication between the characters ? The whole layout of the surrounding future world ? No matter what you loved about it...<br /><br />The Aeon Flux film of late 2005 has nothing of that.<br /><br />Karyn Kusama, the so called \\\"director\\\" of the film, was hopelessly over-strained with transporting the original content to a new film. If you 're not familiar with the original series, you won't understand anything during for the first 60minutes of the film.The story is inscrutable and the vapid characters do not develop during the film.<br /><br />Kusama's attempt to improve the storyline by implementing some rather weak explanatory conversations between the main characters is not only a lame attempt to cover up her flaws as a storyteller , it's simply unworthy of the original \\u00c6ON concept.<br /><br />Charlize Theron might be an attractive woman, but she can't impersonate the \\u00c6ON character. Although she was attached to strings doing action scenes, her lack of talent for physical motion simply ruins the action sequences in the film. The result is a tremendous amount of hectic picture cuts to cover up the sheer lameness of her physique.<br /><br />Forget about all the rest, it's not worth talking about...<br /><br />I give 1point for Ms.Theron showing her boobs and 1point for the nice architectural photography in the film. That's it.\",\n          \"I like Noel Coward, the wit. I like Noel Coward, the play write. I like Noel Coward, the composer and singer, but I loathe Noel Coward the actor.<br /><br />To me this is a man who should have stayed firmly behind the scenes, writing his plays and composing his music and making his profound and hilarious observations. He should never have been allowed in front of a camera.<br /><br />Make no mistake, he is one of the top outstanding talents of the 20th century but the man just couldn't act, and his voice...with it's rolling R's and it's overly round tonal quality...well it could quite easily grate cheese in my opinion.<br /><br />This is one of my least favourite offerings from Coward, as he unconvincingly portrays a psychiatrist embarking on an affair with a much younger woman, made worse by the fact that the much younger woman is an old school friend of his much younger wife.<br /><br />Celia Johnson is as much a joy to watch as ever as Cowards wronged wife. It is her performance that saves this film from abject dullness. I suppose her own little fling in Coward's Brief Encounter four years previously qualified her for this role as she must have raised a few eyebrows playing a such a promiscuous woman and this gave her the chance to win back a few fans and gain some lost sympathy.<br /><br />She was such a wonderful actress and you can see why Noel Coward used her so much in many of his productions.<br /><br />However the rest of the film is drab, badly acted, predictable and on the whole boring to almost arse-clenching level.<br /><br />If its Noel Coward you want then take the time to watch In Which We Serve, Blythe Spirit or This Happy Breed instead. Three Noel Coward treasures. With lovely films like these I suppose we can forgive him for this turkey.<br /><br />I have given this four stars purely for the addition of Miss Johnson, but on the whole I'd avoid this one like the plague.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv('https://raw.githubusercontent.com/aws-samples/aws-machine-learning-university-accelerated-nlp/master/data/final_project/imdb_test.csv', header=0)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n7O1xvmPcHp"
      },
      "source": [
        "## 2. Train a KNN Classifier\n",
        "Here, you will apply pre-processing operations we covered in the class. Then, you can split your dataset to training and validation here. For your first submission, you will use __K Nearest Neighbors Classifier__. It is available [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5f90bOZGPcHp",
        "outputId": "75b5baed-ce1e-4d90-eedc-6ff2b7315d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing the reviewText fields\n",
            "[[648 632]\n",
            " [555 665]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.51      0.52      1280\n",
            "           1       0.51      0.55      0.53      1220\n",
            "\n",
            "    accuracy                           0.53      2500\n",
            "   macro avg       0.53      0.53      0.53      2500\n",
            "weighted avg       0.53      0.53      0.53      2500\n",
            "\n",
            "Accuracy (validation): 0.5252\n"
          ]
        }
      ],
      "source": [
        "# Implement this\n",
        "# Install the library and functions\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import nltk, re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Let's get a list of stop words from the NLTK library\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# These words are important for our problem. We don't want to remove them.\n",
        "excluding = ['against', 'not', 'don', \"don't\",'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
        "             'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\",\n",
        "             'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n",
        "             'needn', \"needn't\",'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren',\n",
        "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "# New stop word list\n",
        "stop_words = [word for word in stop if word not in excluding]\n",
        "\n",
        "snow = SnowballStemmer('english')\n",
        "\n",
        "def process_text(texts):\n",
        "    final_text_list=[]\n",
        "    for sent in texts:\n",
        "\n",
        "        # Check if the sentence is a missing value\n",
        "        if isinstance(sent, str) == False:\n",
        "            sent = \"\"\n",
        "\n",
        "        filtered_sentence=[]\n",
        "\n",
        "        sent = sent.lower() # Lowercase\n",
        "        sent = sent.strip() # Remove leading/trailing whitespace\n",
        "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
        "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
        "\n",
        "        for w in word_tokenize(sent):\n",
        "            # We are applying some custom filtering here, feel free to try different things\n",
        "            # Check if it is not numeric and its length>2 and not in stop words\n",
        "            if(not w.isnumeric()) and (len(w)>2) and (w not in stop_words):\n",
        "                # Stem and add to filtered list\n",
        "                filtered_sentence.append(snow.stem(w))\n",
        "        final_string = \" \".join(filtered_sentence) #final string of cleaned words\n",
        "\n",
        "        final_text_list.append(final_string)\n",
        "\n",
        "    return final_text_list\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X=train_df[[\"text\"]]\n",
        "Y=train_df[\"label\"]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,\n",
        "                                                  Y,\n",
        "                                                  test_size=0.10,\n",
        "                                                  shuffle=True,\n",
        "                                                  random_state=324\n",
        "                                                 )\n",
        "\n",
        "print(\"Processing the reviewText fields\")\n",
        "train_text_list = process_text(X_train[\"text\"].tolist())\n",
        "val_text_list = process_text(X_val[\"text\"].tolist())\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "### PIPELINE ###\n",
        "##########################\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=True,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=10)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rieXB-QtPcHq"
      },
      "source": [
        "## 3. Make predictions on your test dataset\n",
        "\n",
        "Once we select our best performing model, we can use it to make predictions on the test dataset. You can simply use __.fit()__ function with your training data to use the best performing K value and use __.predict()__ with your test data to get your test predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BssNQEfAPcHq",
        "outputId": "b70cbd59-88ae-4e81-f6f3-776618c6f551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST PERFORMING MODEL USED TO PREDICT THE TEST DATA SET: \n",
            " TFIDVECTORIZER USED \n",
            " MAX FEATURES WAS 1000 \n",
            " KNN VALUE WAS 50\n",
            "[[ 3114  9386]\n",
            " [ 1531 10969]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.25      0.36     12500\n",
            "           1       0.54      0.88      0.67     12500\n",
            "\n",
            "    accuracy                           0.56     25000\n",
            "   macro avg       0.60      0.56      0.52     25000\n",
            "weighted avg       0.60      0.56      0.52     25000\n",
            "\n",
            "Accuracy (validation): 0.56332\n"
          ]
        }
      ],
      "source": [
        "# Implement this\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=1000)),\n",
        "    ('knn', KNeighborsClassifier(50))\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "I=test_df[\"text\"]\n",
        "J=test_df[\"label\"]\n",
        "\n",
        "test_predictions = pipeline.predict(I)\n",
        "print(\"BEST PERFORMING MODEL USED TO PREDICT THE TEST DATA SET: \\n TFIDVECTORIZER USED \\n MAX FEATURES WAS 1000 \\n KNN VALUE WAS 50\")\n",
        "print(confusion_matrix(J.values, test_predictions))\n",
        "print(classification_report(J.values, test_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(J.values, test_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Experimentation\n",
        "\n",
        "For each of the following tasks, track both the **weighted F1-score** and **accuracy**:\n",
        "\n",
        "1. **Change the binary parameter in CountVectorizer**: Test both `binary=True` and `binary=False`, and evaluate performance.\n",
        "2. **Switch to TfidfVectorizer**: Replace the CountVectorizer with TfidfVectorizer and compare results.\n",
        "3. **Adjust the max_features**: Experiment with different values of `max_features` for both TfidfVectorizer and CountVectorizer (`binary=True`).\n",
        "4. **Optimize KNN**: Select the best-performing model from task 3 and vary the number of neighbors (`n_neighbors`) in the KNN classifier.\n"
      ],
      "metadata": {
        "id": "Lhp8mXM_Ax8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1\n",
        "\n",
        "# Implement this\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "### PIPELINE ###\n",
        "##########################\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=True,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=10)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE COUNTVECTORIZER IS TRUE\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "\n",
        "### PIPELINE ###\n",
        "##########################\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=False,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=10)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE COUNTVECTORIZER IS FALSE\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))"
      ],
      "metadata": {
        "id": "9RpHvtEWCVB1",
        "outputId": "527a671b-dfb0-4353-eded-aab7a47bb284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " RESULTS WHEN THE COUNTVECTORIZER IS TRUE\n",
            "[[648 632]\n",
            " [555 665]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.51      0.52      1280\n",
            "           1       0.51      0.55      0.53      1220\n",
            "\n",
            "    accuracy                           0.53      2500\n",
            "   macro avg       0.53      0.53      0.53      2500\n",
            "weighted avg       0.53      0.53      0.53      2500\n",
            "\n",
            "Accuracy (validation): 0.5252\n",
            " RESULTS WHEN THE COUNTVECTORIZER IS FALSE\n",
            "[[662 618]\n",
            " [595 625]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.52      0.52      1280\n",
            "           1       0.50      0.51      0.51      1220\n",
            "\n",
            "    accuracy                           0.51      2500\n",
            "   macro avg       0.51      0.51      0.51      2500\n",
            "weighted avg       0.52      0.51      0.51      2500\n",
            "\n",
            "Accuracy (validation): 0.5148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Implement this\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "### PIPELINE ###\n",
        "##########################\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=True,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=10)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE COUNTVECTORIZER IS TRUE\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "\n",
        "### PIPELINE ###\n",
        "##########################\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=False,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=10)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE COUNTVECTORIZER IS FALSE\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "# Task 2\n",
        "\n",
        "# Implement this\n",
        "### PIPELINE ###\n",
        "##########################\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=False,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=10)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN SWITCHED TO TFIDVECTORIZER\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))"
      ],
      "metadata": {
        "id": "6bNcCQ2PCfiu",
        "outputId": "8370b9a0-6cd8-49ee-9cde-14d536d3db02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " RESULTS WHEN THE COUNTVECTORIZER IS TRUE\n",
            "[[648 632]\n",
            " [555 665]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.51      0.52      1280\n",
            "           1       0.51      0.55      0.53      1220\n",
            "\n",
            "    accuracy                           0.53      2500\n",
            "   macro avg       0.53      0.53      0.53      2500\n",
            "weighted avg       0.53      0.53      0.53      2500\n",
            "\n",
            "Accuracy (validation): 0.5252\n",
            " RESULTS WHEN THE COUNTVECTORIZER IS FALSE\n",
            "[[662 618]\n",
            " [595 625]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.52      0.52      1280\n",
            "           1       0.50      0.51      0.51      1220\n",
            "\n",
            "    accuracy                           0.51      2500\n",
            "   macro avg       0.51      0.51      0.51      2500\n",
            "weighted avg       0.52      0.51      0.51      2500\n",
            "\n",
            "Accuracy (validation): 0.5148\n",
            " RESULTS WHEN SWITCHED TO TFIDVECTORIZER\n",
            "[[681 599]\n",
            " [588 632]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.53      0.53      1280\n",
            "           1       0.51      0.52      0.52      1220\n",
            "\n",
            "    accuracy                           0.53      2500\n",
            "   macro avg       0.53      0.53      0.53      2500\n",
            "weighted avg       0.53      0.53      0.53      2500\n",
            "\n",
            "Accuracy (validation): 0.5252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3\n",
        "\n",
        "# Implement this\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=True,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=50)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE COUNTVECTORIZER IS TRUE AND MAX FEATURE IS 50\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=True,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=100)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE COUNTVECTORIZER IS TRUE AND MAX FEATURE IS 100\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=True,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=500)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE COUNTVECTORIZER IS TRUE AND MAX FEATURE IS 500\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    ('text_vect', CountVectorizer(binary=True,\n",
        "    #( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=1000)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE COUNTVECTORIZER IS TRUE AND MAX FEATURE IS 1000\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))"
      ],
      "metadata": {
        "id": "M_bnccPMCgM9",
        "outputId": "ee7e775f-0dcb-4a52-f0f4-e6c7b1d602bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " RESULTS WHEN THE COUNTVECTORIZER IS TRUE AND MAX FEATURE IS 50\n",
            "[[788 492]\n",
            " [474 746]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.62      0.62      1280\n",
            "           1       0.60      0.61      0.61      1220\n",
            "\n",
            "    accuracy                           0.61      2500\n",
            "   macro avg       0.61      0.61      0.61      2500\n",
            "weighted avg       0.61      0.61      0.61      2500\n",
            "\n",
            "Accuracy (validation): 0.6136\n",
            " RESULTS WHEN THE COUNTVECTORIZER IS TRUE AND MAX FEATURE IS 100\n",
            "[[783 497]\n",
            " [442 778]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.61      0.63      1280\n",
            "           1       0.61      0.64      0.62      1220\n",
            "\n",
            "    accuracy                           0.62      2500\n",
            "   macro avg       0.62      0.62      0.62      2500\n",
            "weighted avg       0.63      0.62      0.62      2500\n",
            "\n",
            "Accuracy (validation): 0.6244\n",
            " RESULTS WHEN THE COUNTVECTORIZER IS TRUE AND MAX FEATURE IS 500\n",
            "[[820 460]\n",
            " [428 792]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.64      0.65      1280\n",
            "           1       0.63      0.65      0.64      1220\n",
            "\n",
            "    accuracy                           0.64      2500\n",
            "   macro avg       0.64      0.64      0.64      2500\n",
            "weighted avg       0.65      0.64      0.64      2500\n",
            "\n",
            "Accuracy (validation): 0.6448\n",
            " RESULTS WHEN THE COUNTVECTORIZER IS TRUE AND MAX FEATURE IS 1000\n",
            "[[753 527]\n",
            " [395 825]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.59      0.62      1280\n",
            "           1       0.61      0.68      0.64      1220\n",
            "\n",
            "    accuracy                           0.63      2500\n",
            "   macro avg       0.63      0.63      0.63      2500\n",
            "weighted avg       0.63      0.63      0.63      2500\n",
            "\n",
            "Accuracy (validation): 0.6312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3\n",
        "\n",
        "# Implement this\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=50)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 50\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=100)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 100\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=500)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 500\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=1000)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 1000\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))"
      ],
      "metadata": {
        "id": "ewxiqo-yfFET",
        "outputId": "f5165735-44d0-4287-dfd7-114b136ae3b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 50\n",
            "[[829 451]\n",
            " [441 779]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.65      0.65      1280\n",
            "           1       0.63      0.64      0.64      1220\n",
            "\n",
            "    accuracy                           0.64      2500\n",
            "   macro avg       0.64      0.64      0.64      2500\n",
            "weighted avg       0.64      0.64      0.64      2500\n",
            "\n",
            "Accuracy (validation): 0.6432\n",
            " RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 100\n",
            "[[841 439]\n",
            " [395 825]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.66      0.67      1280\n",
            "           1       0.65      0.68      0.66      1220\n",
            "\n",
            "    accuracy                           0.67      2500\n",
            "   macro avg       0.67      0.67      0.67      2500\n",
            "weighted avg       0.67      0.67      0.67      2500\n",
            "\n",
            "Accuracy (validation): 0.6664\n",
            " RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 500\n",
            "[[870 410]\n",
            " [300 920]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.68      0.71      1280\n",
            "           1       0.69      0.75      0.72      1220\n",
            "\n",
            "    accuracy                           0.72      2500\n",
            "   macro avg       0.72      0.72      0.72      2500\n",
            "weighted avg       0.72      0.72      0.72      2500\n",
            "\n",
            "Accuracy (validation): 0.716\n",
            " RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 1000\n",
            "[[875 405]\n",
            " [299 921]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.68      0.71      1280\n",
            "           1       0.69      0.75      0.72      1220\n",
            "\n",
            "    accuracy                           0.72      2500\n",
            "   macro avg       0.72      0.72      0.72      2500\n",
            "weighted avg       0.72      0.72      0.72      2500\n",
            "\n",
            "Accuracy (validation): 0.7184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best performing model from task three was when the pipeline was set to Tfidvectoriser and the max features was set to a value of 1000. The various values experimented with were (10,50,100,500,100)"
      ],
      "metadata": {
        "id": "WgROIlbYgB6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4\n",
        "\n",
        "# Implement this\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=1000)),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 1000\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=1000)),\n",
        "    ('knn', KNeighborsClassifier(10))\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE TFIDVECTORIZER IS USED \\n MAX FEATURES IS 1000 \\n KNN VALUE IS 10\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=1000)),\n",
        "    ('knn', KNeighborsClassifier(20))\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE TFIDVECTORIZER IS USED \\n MAX FEATURES IS 1000 \\n KNN VALUE IS 20\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))\n",
        "\n",
        "w2v = gensim.models.Word2Vec()\n",
        "pipeline = Pipeline([\n",
        "    #('text_vect', CountVectorizer(binary=True,\n",
        "    ( 'text_vect', TfidfVectorizer(use_idf=True,\n",
        "                                  max_features=1000)),\n",
        "    ('knn', KNeighborsClassifier(50))\n",
        "                                ])\n",
        "\n",
        "\n",
        "# Visualize the pipeline\n",
        "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pipeline\n",
        "\n",
        "# We using lists of processed text fields\n",
        "X_train = train_text_list\n",
        "X_val = val_text_list\n",
        "\n",
        "# Fit the Pipeline to training data\n",
        "pipeline.fit(X_train, y_train.values)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Use the fitted pipeline to make predictions on the validation dataset\n",
        "val_predictions = pipeline.predict(X_val)\n",
        "print(\" RESULTS WHEN THE TFIDVECTORIZER IS USED \\n MAX FEATURES IS 1000 \\n KNN VALUE IS 50\")\n",
        "print(confusion_matrix(y_val.values, val_predictions))\n",
        "print(classification_report(y_val.values, val_predictions))\n",
        "print(\"Accuracy (validation):\", accuracy_score(y_val.values, val_predictions))"
      ],
      "metadata": {
        "id": "OL1koC0RChNf",
        "outputId": "4d2dfcc7-a969-4fec-adb0-d684b7f51184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " RESULTS WHEN THE TFIDVECTORIZER IS USED AND MAX FEATURE IS 1000\n",
            "[[875 405]\n",
            " [299 921]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.68      0.71      1280\n",
            "           1       0.69      0.75      0.72      1220\n",
            "\n",
            "    accuracy                           0.72      2500\n",
            "   macro avg       0.72      0.72      0.72      2500\n",
            "weighted avg       0.72      0.72      0.72      2500\n",
            "\n",
            "Accuracy (validation): 0.7184\n",
            " RESULTS WHEN THE TFIDVECTORIZER IS USED \n",
            " MAX FEATURES IS 1000 \n",
            " KNN VALUE IS 10\n",
            "[[965 315]\n",
            " [347 873]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.75      0.74      1280\n",
            "           1       0.73      0.72      0.73      1220\n",
            "\n",
            "    accuracy                           0.74      2500\n",
            "   macro avg       0.74      0.73      0.73      2500\n",
            "weighted avg       0.74      0.74      0.74      2500\n",
            "\n",
            "Accuracy (validation): 0.7352\n",
            " RESULTS WHEN THE TFIDVECTORIZER IS USED \n",
            " MAX FEATURES IS 1000 \n",
            " KNN VALUE IS 20\n",
            "[[954 326]\n",
            " [285 935]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.75      0.76      1280\n",
            "           1       0.74      0.77      0.75      1220\n",
            "\n",
            "    accuracy                           0.76      2500\n",
            "   macro avg       0.76      0.76      0.76      2500\n",
            "weighted avg       0.76      0.76      0.76      2500\n",
            "\n",
            "Accuracy (validation): 0.7556\n",
            " RESULTS WHEN THE TFIDVECTORIZER IS USED \n",
            " MAX FEATURES IS 1000 \n",
            " KNN VALUE IS 50\n",
            "[[956 324]\n",
            " [229 991]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.75      0.78      1280\n",
            "           1       0.75      0.81      0.78      1220\n",
            "\n",
            "    accuracy                           0.78      2500\n",
            "   macro avg       0.78      0.78      0.78      2500\n",
            "weighted avg       0.78      0.78      0.78      2500\n",
            "\n",
            "Accuracy (validation): 0.7788\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}